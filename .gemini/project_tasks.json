{
  "project_title": "Gemini CLI Document Worker",
  "version": "1.0",
  "tasks": [
    {
      "task_id": "01-worker-setup",
      "title": "Set up the Cloudflare Worker Project",
      "description": "Initialize a new Workers project, configure it with the necessary bindings, and set up a basic fetch handler to handle routing.",
      "subtasks": [
        {
          "subtask_id": "01.1-initialize-project",
          "title": "Initialize a new Worker project with Wrangler",
          "instructions": "Use the command `npm create cloudflare@latest -- [project-name]` and select the 'Hello World' example with TypeScript. Move into the new directory with `cd [project-name]`."
        },
        {
          "subtask_id": "01.2-configure-wrangler",
          "title": "Configure Wrangler.toml with bindings",
          "instructions": "In the `wrangler.toml` file, add bindings for R2, D1, Worker AI, and Vectorize. The bindings should include `name`, `class_name` (for D1/DO), `bucket_name` (for R2), `index_name` (for Vectorize), and `binding = 'AI'`. The D1 and Vectorize bindings are crucial for data storage and search, respectively."
        },
        {
          "subtask_id": "01.3-define-handlers",
          "title": "Define the main `fetch` handler and routing logic",
          "instructions": "In `src/index.ts`, create a main `fetch` handler. Implement logic to parse the request URL pathname and route requests to the appropriate handlers for `/`, `/<fileId>`, `/<fileId>/embeddings`, `/<fileId>/ask`, and `/<fileId>/semantic`. Use a router like Hono for clean routing."
        }
      ]
    },
    {
      "task_id": "02-document-ingestion",
      "title": "Implement Document Ingestion via POST endpoint",
      "description": "Create the API endpoint to receive document uploads, process them, and store the relevant data in R2, D1, and Vectorize.",
      "subtasks": [
        {
          "subtask_id": "02.1-handle-upload",
          "title": "Create a `POST /` endpoint to handle file uploads",
          "instructions": "This handler should use `request.formData()` to get the uploaded file. A `TypeError` can occur if `request.formData()` is called more than once, so clone the request if needed."
        },
        {
          "subtask_id": "02.2-store-raw-file",
          "title": "Store the raw file in R2",
          "instructions": "After receiving the file, use `env.R2.put(key, file)` to store it in the configured R2 bucket. The key should be a unique `fileId` generated by the worker (e.g., using `crypto.randomUUID()`)."
        },
        {
          "subtask_id": "02.3-extract-text-and-embed",
          "title": "Extract text and generate embeddings with Worker AI",
          "instructions": "Use `env.AI.toMarkdown()` with the file Blob to perform text extraction (OCR). Then, use a text embedding model like `@cf/baai/bge-base-en-v1.5` to convert the extracted text into vector embeddings. The embedding generation process can be batched for efficiency."
        },
        {
          "subtask_id": "02.4-store-metadata",
          "title": "Store metadata in D1 and Vectorize",
          "instructions": "In D1, store the `fileId`, original filename, R2 object key, and extracted text. Ensure the schema is defined. In Vectorize, use `env.VECTOR_INDEX.upsert()` to store the generated embeddings, linking them to the `fileId` as metadata. Remember to handle rate limits with exponential backoff if necessary when calling APIs."
        },
        {
          "subtask_id": "02.5-return-url",
          "title": "Return the unique URL to the user",
          "instructions": "The `POST /` endpoint should respond with a JSON object containing the unique URL (`https://your-worker.workers.dev/<fileId>`)."
        }
      ]
    },
    {
      "task_id": "03-api-endpoints",
      "title": "Develop Public-Facing Endpoints",
      "description": "Implement the various `GET` and `POST` endpoints for interacting with stored documents, including text display, embeddings, and chat/search functionalities.",
      "subtasks": [
        {
          "subtask_id": "03.1-get-file-content",
          "title": "Implement `GET /<fileId>` to return plain text",
          "instructions": "This handler should retrieve the document metadata from D1 using the `fileId`. It should then return the extracted text with a `Content-Type: text/plain` header."
        },
        {
          "subtask_id": "03.2-get-embeddings",
          "title": "Implement `GET /<fileId>/embeddings` to return JSON",
          "instructions": "This handler should fetch the embeddings from the Vectorize index using the `fileId`. Return the embedding vector in a JSON response with a `Content-Type: application/json` header."
        },
        {
          "subtask_id": "03.3-create-frontend-for-ask",
          "title": "Implement `GET /<fileId>/ask` to serve a chat UI",
          "instructions": "This endpoint should return a basic HTML page with a chat interface. The UI will have a text input for the user's query and a display area for the AI's response. The frontend should handle `POST` requests to the same URL."
        },
        {
          "subtask_id": "03.4-handle-ask-post",
          "title": "Implement `POST /<fileId>/ask` to query with Worker AI",
          "instructions": "This handler will receive a JSON payload with a `query`. It should fetch the document text from D1, create a prompt for a text generation model (e.g., `@cf/meta/llama-3.1-8b-instruct`), and send both the query and the document content to the model as context. The model's response should be returned as a JSON object."
        },
        {
          "subtask_id": "03.5-create-frontend-for-semantic",
          "title": "Implement `GET /<fileId>/semantic` to serve a search UI",
          "instructions": "Create another simple HTML page with a search-focused UI, similar to the chat interface but tailored for displaying semantic search results (e.g., listing relevant document chunks)."
        },
        {
          "subtask_id": "03.6-handle-semantic-post",
          "title": "Implement `POST /<fileId>/semantic` for vector search",
          "instructions": "This handler should receive a `query`, convert it to an embedding using `@cf/baai/bge-base-en-v1.5`, and then query the Vectorize index for the most similar vectors. The response should return the associated metadata or document chunks retrieved from D1 based on the vector search results."
        }
      ]
    },
    {
      "task_id": "04-deployment-testing",
      "title": "Deploy and Test the Worker",
      "description": "Finalize the worker for deployment and perform tests to ensure all functionality works as expected.",
      "subtasks": [
        {
          "subtask_id": "04.1-local-dev",
          "title": "Test locally with Wrangler",
          "instructions": "Use `npx wrangler dev` to run the worker locally. This simulates the bindings. To test the worker's functionality, use `curl` commands or a browser to hit the various endpoints."
        },
        {
          "subtask_id": "04.2-deploy",
          "title": "Deploy the worker to Cloudflare",
          "instructions": "After local testing, run `npx wrangler deploy` to deploy the Worker globally. This command will also set up the bindings for your live production environment."
        },
        {
          "subtask_id": "04.3-verify-endpoints",
          "title": "Verify live endpoints",
          "instructions": "Confirm that all public-facing endpoints are working correctly by accessing them via the deployed `*.workers.dev` URL."
        }
      ]
    }
  ]
}

